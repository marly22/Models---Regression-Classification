#logistic regression
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
#we train dataset on Age &Estimated Salary
dataset = dataset[, 3:5]

# Splitting the dataset into the Training set and Test set
#we install packages , the library
install.packages('caTools')
library(caTools)
set.seed(123)
#split on y response variable Purchased
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

#Feature Scaling; coulumns age & estimated salary scale between O and 1
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2] = scale(test_set[,1:2])

#Fitting Logistic Regression to the Training Set
#glm - generalized linear model, family for Logistis is always binomial
#we fit classifier to our training set
classifier = glm( formula = Purchased  ~ .,
                  family = binomial,
                  data = training_set)
#predicting the Test set results, create vector of predicted probabilities 
#newdata without response variable , we obtain
#probabilities of all my test set observations
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3] )
#we want a vector however that gives us 0 or 1, we create another vector
#transforming prob_pred in 0 and 1, based on condition that if
#probability is higher than 0.5 , it means that a user probably buy SUV CAR(1)
#so first we put what we want if condition is true, and then alternativa result
y_pred = ifelse(prob_pred > 0.5, 1, 0)
#basically we compare predicted values of y to real values of y of test set
#accuracy of our model
misClasificError <- mean(y_pred != test_set$Purchased)
print(paste('Accuracy',1-misClasificError))

#assessing the predictive ability of the model
#evaluating the accuracy of the model, we compare 
#predicted values with real values of test set
#As a last step, we are going to plot the ROC curve and calculate 
#the AUC (area under the curve) which are typical performance measurements 
#for a binary classifier.
#The ROC is a curve generated by plotting the true positive rate (TPR) 
#against the false positive rate (FPR) at various threshold settings
#while the AUC is the area under the ROC curve.
#As a rule of thumb, a model with good predictive ability 
#should have an AUC closer to 1 (1 is ideal) than to 0.5.
install.packages('ROCR')
library(ROCR)
library(ggplot2)
preds_list <- list(y_pred)
m <- length(preds_list)
actuals_list <- rep(list(test_set$Purchased), m)
pred <- prediction(preds_list, actuals_list)
rocs <- performance(pred, "tpr", "fpr")
plot(rocs, col = as.list(1:m), main = "Test Set ROC Curves")
auc <- performance(pred, measure = "auc")
auc <- auc@y.values[[1]]
auc


#evaluate the prediction model with confusion matrix
#Making the Confusion Matrix, 1st real values  + predicted
cm = table(test_set[,3], y_pred)
# 57, 56 correct predictions ; 10 and 7 are incorrect

#Visualizing the training set results
install.packages('ElemStatLearn')
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2) # this is matrix
colnames(grid_set) = c('Age', 'EstimatedSalary') #giving names to matrix col
prob_set = predict(classifier, type= 'response', newdata = grid_set) #we predict on all imagianry pixel points
y_grid = ifelse(prob_set >0.5, 1, 0) #we transform into 0 and 1 prob_set
plot(set[, -3],
     main = 'Logistic regression (Training set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'Spring Green 3', 'Tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'Green 4', 'Red 3'))

#the idea is to catch the user to the right category
#red and green regions are prediction regions according to our classifier
#2 regions are separated by prediction boundary

#for new predictions , visualizing TEST SET
#quite good results, majority of points is in the right prediction regions
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type= 'response', newdata = grid_set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
     main = 'Logistic regression (Test set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'Spring Green 3', 'Tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'Green 4', 'Red 3'))



